{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicker = False\n",
    "if clicker:\n",
    "    cyberzoo_green_width = 7\n",
    "    cyberzoo_green_length = 7\n",
    "    z_min = 0\n",
    "\n",
    "    corner_coordinates = {\n",
    "                'A': {'x' : cyberzoo_green_width/2,\n",
    "                    'y' : cyberzoo_green_length/2,\n",
    "                    'z' : z_min},\n",
    "                'B': {'x' : -cyberzoo_green_width/2,\n",
    "                    'y' : cyberzoo_green_length/2,\n",
    "                    'z' : z_min},\n",
    "                'C': {'x' : -cyberzoo_green_width/2,\n",
    "                    'y' : -cyberzoo_green_length/2,\n",
    "                    'z' : z_min},\n",
    "                'D': {'x' : cyberzoo_green_width/2,\n",
    "                    'y' : -cyberzoo_green_length/2,\n",
    "                    'z' : z_min}\n",
    "            }\n",
    "\n",
    "\n",
    "    # Initialize global variables\n",
    "    point_clicked_img = None\n",
    "    img = None\n",
    "\n",
    "    # Callback function for mouse events\n",
    "    def click_event(event, x, y, flags, param):\n",
    "        global point_clicked_img, img\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:  # Left mouse button clicked\n",
    "            point_clicked_img = ((x, y))  # Append the (x, y) tuple to the list\n",
    "            print(f'Coordinates: ({x}, {y})')  # Print coordinates of the click\n",
    "            cv2.circle(img, (x, y), 5, (255, 0, 0), -1)  # Mark the clicked point with a blue circle\n",
    "            \n",
    "            cv2.imshow('image', img)  # Show the image with the marked point\n",
    "        return point_clicked_img\n",
    "\n",
    "    def clicker_call(image_path):\n",
    "        global img, point_clicked_img\n",
    "        # Load your image\n",
    "        img = cv2.imread(image_path)\n",
    "        # Rotate the image 90 counter\n",
    "        img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        # Make image brighter\n",
    "        img = cv2.convertScaleAbs(img, alpha=1.5, beta=0)\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "        # Set mouse callback function for 'image' window\n",
    "        cv2.setMouseCallback('image', click_event)\n",
    "\n",
    "        # What to press 'a' 'b' 'c' or 'd' and go into a if statement\n",
    "        \n",
    "        # Back is the closed way opposite the netted wall\n",
    "        # A : right back\n",
    "        # B : right front\n",
    "        # C : left front\n",
    "        # D : left back\n",
    "\n",
    "        k = cv2.waitKey(0)\n",
    "        if k == ord('a'):\n",
    "            # Cyberzoo coordinate a\n",
    "            X = corner_coordinates['A']['x']\n",
    "            Y = corner_coordinates['A']['y']\n",
    "            Z = corner_coordinates['A']['z']\n",
    "            point_clicked_xyz = (X, Y, Z)\n",
    "            corner_label = 'A'\n",
    "        if k == ord('b'):\n",
    "            # Cyberzoo coordinate b\n",
    "            X = corner_coordinates['B']['x']\n",
    "            Y = corner_coordinates['B']['y']\n",
    "            Z = corner_coordinates['B']['z']\n",
    "            point_clicked_xyz = (X, Y, Z)\n",
    "            corner_label = 'B'\n",
    "\n",
    "        if k == ord('c'):\n",
    "            # Cyberzoo coordinate c\n",
    "            X = corner_coordinates['C']['x']\n",
    "            Y = corner_coordinates['C']['y']\n",
    "            Z = corner_coordinates['C']['z']\n",
    "            point_clicked_xyz = (X, Y, Z)\n",
    "            corner_label = 'C'\n",
    "        if k == ord('d'):\n",
    "            # Cyberzoo coordinate d\n",
    "            X = corner_coordinates['D']['x']\n",
    "            Y = corner_coordinates['D']['y']\n",
    "            Z = corner_coordinates['D']['z']\n",
    "            point_clicked_xyz = (X, Y, Z)\n",
    "            corner_label = 'D'  \n",
    "\n",
    "        cv2.waitKey(0)  # Wait for a key press to exit\n",
    "        cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "\n",
    "        # Optionally, print all clicked points\n",
    "        print('clicked point:', point_clicked_img)\n",
    "\n",
    "        return point_clicked_img, point_clicked_xyz, corner_label\n",
    "\n",
    "\n",
    "    images_path = r\"C:\\Users\\Jonathan van Zyl\\Documents\\GitHub\\paparazzi\\Data_gitignore\\AE4317_2019_datasets\\cyberzoo_poles_panels\\20190121-140205\"\n",
    "    file_path = \"Data_gitignore/AE4317_2019_datasets/cyberzoo_poles_panels/20190121-140303.csv\"\n",
    "    frame_files = sorted(os.listdir(images_path))\n",
    "\n",
    "    no_images = len(frame_files)\n",
    "    max_iters = 200\n",
    "    steps_between_image = int(no_images/max_iters)\n",
    "    stop_iter = steps_between_image*max_iters\n",
    "\n",
    "    print(0, stop_iter, steps_between_image)\n",
    "    # Open the CSV file in write mode\n",
    "    with open('outputdos.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write the header\n",
    "        writer.writerow([\"image_name\", \"image_x\", \"image_y\", \"x\", \"y\", \"z\", \"corner_label\"])\n",
    "        for i in range(0, stop_iter, steps_between_image):\n",
    "            \n",
    "            image_path = os.path.join(images_path, frame_files[i])\n",
    "\n",
    "            point_clicked_img, point_clicked_xyz, corner_label = clicker_call(image_path)\n",
    "\n",
    "            print('point clicked image:', point_clicked_img)\n",
    "            print('point clicked xyz:', point_clicked_xyz)\n",
    "\n",
    "            image_name = frame_files[i]\n",
    "\n",
    "            # Write the data to the CSV file\n",
    "            writer.writerow([image_name, point_clicked_img[0], point_clicked_img[1], point_clicked_xyz[0], point_clicked_xyz[1], point_clicked_xyz[2], corner_label])\n",
    "\n",
    "            # Stop if q is pressed\n",
    "            k = cv2.waitKey(0)\n",
    "            if k == ord('q'):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already rotate everything to the camera frame\n",
    "from projection_functions import Camera, StateVector, VideoFeed\n",
    "# Loop over all jpgs\n",
    "'''\n",
    "image_name,time,x_pos,y_pos,z_pos,theta,psi,phi\n",
    "100049163.jpg,100.049163,0.078125,-1.066406,-1.003906,-0.003436465540194465,0.4858215344598055,0.008807465540194464\n",
    "100282495.jpg,100.282495,0.179688,-1.0,-0.9766836186770428,-0.004883,0.4856035953307393,0.008781404669260704\n",
    "100482507.jpg,100.482507,0.25,-0.949219,-0.96875,-0.007677832480032774,0.485107,0.005017167519967227\n",
    "100715833.jpg,100.715833,0.339844,-0.886719,-0.960938,-0.007324,0.485107,0.005050384300061657\n",
    "100982494.jpg,100.982494,0.457031,-0.808594,-0.960938,-0.009118506195596517,0.484863,0.0028570123911930327\n",
    "'''\n",
    "# read the csv file: StateVector.csv and extract\n",
    "\n",
    "\n",
    "def apply_camera_model(predicted_params, points_3d, index):\n",
    "    file_path = r\"C:\\Users\\Jonathan van Zyl\\Documents\\GitHub\\paparazzi\\COMPUTERVISIONSIM\\Projection\\Images\\StateVector.csv\"\n",
    "    image_path = r\"C:\\Users\\Jonathan van Zyl\\Documents\\GitHub\\paparazzi\\COMPUTERVISIONSIM\\Projection\\Images\"\n",
    "\n",
    "    \n",
    "    points_2d, time = apply_camera_model_sub(index, points_3d, file_path, image_path, predicted_parameters)\n",
    "\n",
    "    return points_2d, time\n",
    "\n",
    "def own_fisheye_project(predicted_parameters, points3d_camera):\n",
    "    # Unpack predicted parameters\n",
    "        predicted_parameters = predicted_parameters.unsqueeze(0)\n",
    "        f_x, f_y, c_x, c_y, k1, k2, k3, p_1 = predicted_parameters[0]\n",
    "        X = points3d_camera[0]\n",
    "        Y = points3d_camera[1]\n",
    "        Z = points3d_camera[2]\n",
    "\n",
    "        a = X / Z\n",
    "        b = Y / Z\n",
    "        r = np.sqrt(a**2 + b**2)\n",
    "\n",
    "\n",
    "        theta = np.arctan(r)\n",
    "        theta_d = theta * (1 + k1 * theta**2 + k2 * theta**4 + k3 * theta**6)\n",
    "        x = theta_d/r * a\n",
    "        y = theta_d/r * b\n",
    "\n",
    "\n",
    "        u = f_x * x + c_x\n",
    "        v = f_y * y + c_y\n",
    "\n",
    "        # Stack the 2D points into a single tensor\n",
    "        points_2d = torch.stack([u, v], dim=-1)\n",
    "\n",
    "        img_width = 240\n",
    "        img_height = 520\n",
    "\n",
    "        # Normalise the points\n",
    "        points_2d[0] = points_2d[0] / img_width\n",
    "        points_2d[1] = points_2d[1] / img_height\n",
    "\n",
    "        return points_2d\n",
    "\n",
    "def point3DDrone_to_point3DCamera(point_3D_Drone):\n",
    "    '''\n",
    "    Drone Frame (a/c frame):\n",
    "    - X : Forward\n",
    "    - Y : Right (maybe left)\n",
    "    - Z : Down\n",
    "\n",
    "    Camera Frame:\n",
    "    - X : Right\n",
    "    - Y : Down\n",
    "    - Z : Forward\n",
    "    '''\n",
    "    \n",
    "    X_drone = point_3D_Drone[0][0]\n",
    "    Y_drone = point_3D_Drone[1][0]\n",
    "    Z_drone = point_3D_Drone[2][0]\n",
    "    \n",
    "    X_camera = Y_drone\n",
    "    Y_camera = Z_drone\n",
    "    Z_camera = X_drone\n",
    "\n",
    "    point_3D_Camera = np.array([X_camera, Y_camera, Z_camera])\n",
    "\n",
    "    return point_3D_Camera\n",
    "\n",
    "\n",
    "def apply_camera_model_sub(index, points_3d_World, file_path, image_path, predicted_parameters):\n",
    "    # Create a state vector object\n",
    "    state_vector = StateVector(file_path)\n",
    "\n",
    "    # Create a camera object\n",
    "    camera_front = Camera()\n",
    "\n",
    "    # Load the image\n",
    "    images = VideoFeed(image_path)\n",
    "\n",
    "    # Rotate the image\n",
    "    images.image_rotate_90_counter()\n",
    "    images.index = index\n",
    "    images.image_current = images.image_read(index)\n",
    "    images.image_rotate_90_counter()\n",
    "\n",
    "\n",
    "\n",
    "    time = images.find_time()\n",
    "    # update the camera object\n",
    "    camera_front.update_state_vector(state_vector, time)\n",
    "\n",
    "\n",
    "    # Create the projection\n",
    "    # Project the cyberzoo points\n",
    "    # Convert points3d_cyberzoo elements to a numpy array of type float32 and reshape to have 3 channels\n",
    "    points_3d_World = np.array(points_3d_World, dtype=np.float32).reshape(-1, 3)\n",
    "    point3D_Drone = camera_front.point3DWorld_to_point3D_Drone(points_3d_World)\n",
    "    point3D_Camera = point3DDrone_to_point3DCamera(point3D_Drone)\n",
    "\n",
    "    # Project the points\n",
    "    points_2d = own_fisheye_project(predicted_parameters, point3D_Camera)\n",
    "\n",
    "    img_width = 240\n",
    "    img_height = 520\n",
    "\n",
    "    # Normalise the points\n",
    "    points_2d[0] = points_2d[0] / img_width\n",
    "    points_2d[1] = points_2d[1] / img_height\n",
    "    \n",
    "\n",
    "    return points_2d, time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CameraParameterEstimator(nn.Module):\n",
    "    def __init__(self, initial_params):\n",
    "        super(CameraParameterEstimator, self).__init__()\n",
    "        #self.fc1 = nn.Linear(3, 512)  # 3 input features (X_c, Y_c, Z_c)\n",
    "        #self.fc2 = nn.Linear(512, 256)\n",
    "        #self.fc3 = nn.Linear(256, 128)\n",
    "        #self.fc4 = nn.Linear(128, 64)\n",
    "        #self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc1 = nn.Linear(3, 8)  # 3 input features (X_c, Y_c, Z_c)\n",
    "        self.fc2 = nn.Linear(8, 32)\n",
    "        self.fc6 = nn.Linear(32, 8)  # 8 output features (f_x, f_y, c_x, c_y, k1, k2, k3, p_1)\n",
    "\n",
    "        # Initialize fc5 weights with initial_params\n",
    "        with torch.no_grad():\n",
    "            self.fc6.bias = nn.Parameter(torch.tensor(initial_params))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        #x = torch.relu(self.fc3(x))\n",
    "        #x = torch.relu(self.fc4(x))\n",
    "        #x = torch.relu(self.fc5(x))\n",
    "        output = self.fc6(x)\n",
    "\n",
    "        # Apply custom transformation to the last five outputs so they are between -0.1 and 0.1\n",
    "        #output[:, 4:] = 0.4 * torch.sigmoid(output[:, 4:]) - 0.1\n",
    "\n",
    "        # Apply custom transformation to first four outputs so are between 0 and 200, 200 added in camera model\n",
    "        #output[:, :4] = 500 * torch.sigmoid(output[:, :4])\n",
    "        \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_initial_guess = np.array([[323.94986777, 0, 265.6212057 ],\n",
    "                  [ 0, 324.58989285, 213.41963136],\n",
    "                  [ 0, 0, 1 ]])\n",
    "        \n",
    "D_initial_guess = np.array([[-0.03146083],\n",
    "                  [-0.03191633],\n",
    "                  [ 0.05678013],\n",
    "                  [-0.04003636]])\n",
    "\n",
    "# initial_params : [f_x, f_y, c_x, c_y, k1, k2, k3, p_1, p_2]\n",
    "f_x = K_initial_guess[0, 0]\n",
    "f_y = K_initial_guess[1, 1]\n",
    "c_x = K_initial_guess[0, 2]\n",
    "c_y = K_initial_guess[1, 2]\n",
    "k1, k2, k3, p_1= D_initial_guess\n",
    "initial_params = [f_x, f_y, c_x, c_y, k1[0], k2[0], k3[0], p_1[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['100049163.', 226.0, 156.0, 3.5], ['100282495.', 231.0, 155.0, 3.5], ['100482507.', 231.0, 156.0, 3.5], ['100715833.', 227.0, 157.0, 3.5], ['100982494.', 229.0, 158.0, 3.5], ['101215830.', 223.0, 159.0, 3.5], ['101449184.', 223.0, 160.0, 3.5], ['101682492.', 222.0, 161.0, 3.5], ['101915820.', 218.0, 164.0, 3.5], ['102149155.', 219.0, 166.0, 3.5], ['102382486.', 219.0, 166.0, 3.5], ['102615813.', 220.0, 166.0, 3.5], ['102849149.', 215.0, 172.0, 3.5], ['103082474.', 213.0, 174.0, 3.5], ['103315832.', 213.0, 173.0, 3.5], ['103549134.', 214.0, 178.0, 3.5], ['103782482.', 213.0, 186.0, 3.5], ['103982472.', 207.0, 204.0, 3.5], ['104215805.', 209.0, 213.0, 3.5], ['104449137.', 210.0, 206.0, 3.5], ['104682471.', 206.0, 200.0, 3.5], ['104915799.', 202.0, 198.0, 3.5], ['105149136.', 202.0, 198.0, 3.5], ['105382468.', 201.0, 193.0, 3.5], ['105615793.', 200.0, 191.0, 3.5], ['105849117.', 204.0, 192.0, 3.5], ['106049124.', 200.0, 191.0, 3.5], ['106282449.', 200.0, 191.0, 3.5], ['106515776.', 201.0, 191.0, 3.5], ['106715785.', 201.0, 191.0, 3.5], ['106949116.', 201.0, 191.0, 3.5], ['107182448.', 207.0, 192.0, 3.5], ['107415764.', 209.0, 191.0, 3.5], ['107649095.', 207.0, 179.0, 3.5], ['107882434.', 207.0, 167.0, 3.5], ['108115758.', 205.0, 154.0, 3.5], ['108349084.', 204.0, 147.0, 3.5], ['108582419.', 198.0, 136.0, 3.5], ['108815749.', 197.0, 130.0, 3.5], ['109049081.', 194.0, 123.0, 3.5], ['109282416.', 194.0, 113.0, 3.5], ['109515746.', 194.0, 108.0, 3.5], ['109749075.', 196.0, 104.0, 3.5], ['109949080.', 196.0, 104.0, 3.5], ['110182409.', 196.0, 104.0, 3.5], ['110449070.', 196.0, 104.0, 3.5], ['110649074.', 196.0, 104.0, 3.5], ['110882428.', 196.0, 104.0, 3.5], ['111115735.', 196.0, 104.0, 3.5], ['111349063.', 196.0, 104.0, 3.5], ['111549065.', 196.0, 104.0, 3.5], ['111782398.', 196.0, 104.0, 3.5], ['112015728.', 196.0, 104.0, 3.5], ['112282388.', 196.0, 103.0, 3.5], ['112515718.', 195.0, 103.0, 3.5], ['112749047.', 194.0, 107.0, 3.5], ['112949055.', 194.0, 107.0, 3.5], ['113182384.', 196.0, 104.0, 3.5], ['113449057.', 196.0, 105.0, 3.5], ['60582822.', 428.0, 117.0, 3.5], ['60849474.', 429.0, 114.0, 3.5], ['61082806.', 430.0, 114.0, 3.5], ['61316162.', 429.0, 116.0, 3.5], ['61549464.', 431.0, 114.0, 3.5], ['61749486.', 431.0, 114.0, 3.5], ['61982804.', 431.0, 114.0, 3.5], ['62216131.', 431.0, 114.0, 3.5], ['62449470.', 431.0, 114.0, 3.5], ['62682793.', 431.0, 114.0, 3.5], ['62916121.', 431.0, 114.0, 3.5], ['63116128.', 431.0, 114.0, 3.5], ['63349460.', 431.0, 114.0, 3.5], ['63582791.', 431.0, 114.0, 3.5], ['63816116.', 431.0, 114.0, 3.5], ['64016121.', 431.0, 114.0, 3.5], ['64249472.', 431.0, 114.0, 3.5], ['64482790.', 431.0, 114.0, 3.5], ['64716106.', 431.0, 114.0, 3.5], ['64949444.', 431.0, 114.0, 3.5], ['65182767.', 431.0, 114.0, 3.5], ['65416095.', 431.0, 114.0, 3.5], ['65649432.', 431.0, 114.0, 3.5], ['65882759.', 431.0, 114.0, 3.5], ['66116087.', 431.0, 114.0, 3.5], ['66349421.', 431.0, 114.0, 3.5], ['66582829.', 394.0, 126.0, 3.5], ['66849432.', 347.0, 132.0, 3.5], ['67082766.', 300.0, 139.0, 3.5], ['67316096.', 287.0, 144.0, 3.5], ['67582755.', 288.0, 148.0, 3.5], ['67782767.', 295.0, 150.0, 3.5], ['68016093.', 293.0, 148.0, 3.5], ['68249423.', 289.0, 140.0, 3.5], ['68482746.', 288.0, 138.0, 3.5], ['68716091.', 286.0, 133.0, 3.5], ['68949420.', 287.0, 134.0, 3.5], ['69182748.', 290.0, 138.0, 3.5], ['69416070.', 288.0, 137.0, 3.5], ['69616081.', 285.0, 141.0, 3.5], ['69849411.', 293.0, 144.0, 3.5], ['70082741.', 299.0, 145.0, 3.5], ['70349401.', 299.0, 146.0, 3.5], ['70582738.', 294.0, 148.0, 3.5], ['70816067.', 291.0, 151.0, 3.5], ['71016067.', 295.0, 148.0, 3.5], ['71249399.', 293.0, 152.0, 3.5], ['71482721.', 293.0, 152.0, 3.5], ['71716069.', 230.0, 112.0, 3.5], ['71949399.', 241.0, 130.0, 3.5], ['72216067.', 241.0, 139.0, 3.5], ['72482714.', 240.0, 150.0, 3.5], ['72716061.', 240.0, 150.0, 3.5], ['72949406.', 241.0, 154.0, 3.5], ['73149383.', 242.0, 157.0, 3.5], ['73382713.', 236.0, 160.0, 3.5], ['73649375.', 236.0, 160.0, 3.5], ['73882714.', 237.0, 166.0, 3.5], ['74149368.', 237.0, 166.0, 3.5], ['74349374.', 235.0, 166.0, 3.5], ['74582713.', 238.0, 169.0, 3.5], ['74849368.', 236.0, 174.0, 3.5], ['75082704.', 235.0, 178.0, 3.5], ['75316029.', 235.0, 178.0, 3.5], ['75549355.', 235.0, 182.0, 3.5], ['75816027.', 234.0, 184.0, 3.5], ['76049354.', 235.0, 189.0, 3.5], ['76282685.', 233.0, 191.0, 3.5], ['76549347.', 233.0, 192.0, 3.5], ['76749356.', 231.0, 193.0, 3.5], ['77016019.', 233.0, 199.0, 3.5], ['77249352.', 227.0, 204.0, 3.5], ['77516007.', 227.0, 204.0, 3.5], ['77716014.', 490.0, 182.0, -3.5], ['77949344.', 346.0, 160.0, -3.5], ['78149345.', 250.0, 162.0, -3.5], ['78382680.', 225.0, 173.0, -3.5], ['78616008.', 261.0, 182.0, -3.5], ['78849330.', 276.0, 189.0, -3.5], ['79082666.', 269.0, 187.0, -3.5], ['79316008.', 264.0, 188.0, -3.5], ['79549334.', 261.0, 192.0, -3.5], ['79782666.', 261.0, 192.0, -3.5], ['80049322.', 259.0, 190.0, -3.5], ['80249343.', 259.0, 194.0, -3.5], ['80482671.', 258.0, 196.0, -3.5], ['80749322.', 258.0, 196.0, -3.5], ['80982655.', 258.0, 196.0, -3.5], ['81215978.', 259.0, 198.0, -3.5], ['81449324.', 259.0, 203.0, -3.5], ['81715974.', 265.0, 201.0, -3.5], ['81915980.', 265.0, 201.0, -3.5], ['82149308.', 262.0, 203.0, -3.5], ['82415970.', 259.0, 207.0, -3.5], ['82615978.', 259.0, 210.0, -3.5], ['82882636.', 262.0, 217.0, -3.5], ['83115963.', 266.0, 221.0, -3.5], ['83349296.', 263.0, 225.0, -3.5], ['83549303.', 248.0, 229.0, -3.5], ['83749299.', 222.0, 192.0, -3.5], ['83982634.', 508.0, 175.0, -3.5], ['84215967.', 355.0, 157.0, -3.5], ['84449293.', 244.0, 151.0, -3.5], ['84649296.', 228.0, 160.0, -3.5], ['84882627.', 253.0, 168.0, -3.5], ['85115956.', 279.0, 176.0, -3.5], ['85349288.', 268.0, 169.0, -3.5], ['85549284.', 267.0, 174.0, -3.5], ['85782616.', 267.0, 178.0, -3.5], ['86015974.', 268.0, 174.0, -3.5], ['86249290.', 267.0, 173.0, -3.5], ['86482617.', 264.0, 171.0, -3.5], ['86682611.', 267.0, 173.0, -3.5], ['86915940.', 263.0, 173.0, -3.5], ['87149268.', 262.0, 171.0, -3.5], ['87382599.', 262.0, 171.0, -3.5], ['87615937.', 262.0, 177.0, -3.5], ['87849266.', 258.0, 174.0, -3.5], ['88049267.', 261.0, 177.0, -3.5], ['88282598.', 261.0, 177.0, -3.5], ['88515921.', 261.0, 177.0, -3.5], ['88749255.', 257.0, 185.0, -3.5], ['88982608.', 261.0, 185.0, -3.5], ['89215917.', 260.0, 188.0, -3.5], ['89449255.', 261.0, 191.0, -3.5], ['89649257.', 261.0, 191.0, -3.5], ['89882587.', 261.0, 191.0, -3.5], ['90115924.', 261.0, 191.0, -3.5], ['90349255.', 259.0, 197.0, -3.5], ['90582579.', 256.0, 202.0, -3.5], ['90815914.', 258.0, 210.0, -3.5], ['91049241.', 257.0, 211.0, -3.5], ['91282568.', 258.0, 214.0, -3.5], ['91515901.', 260.0, 218.0, -3.5], ['91715908.', 260.0, 223.0, -3.5], ['91949236.', 172.0, 237.0, -3.5], ['92182569.', 502.0, 153.0, 3.5], ['92415908.', 348.0, 127.0, 3.5], ['92615903.', 228.0, 132.0, 3.5], ['92849241.', 171.0, 143.0, 3.5], ['93082557.', 197.0, 160.0, 3.5]]\n",
      "[100049163.0, 100282495.0, 100482507.0, 100715833.0, 100982494.0, 101215830.0, 101449184.0, 101682492.0, 101915820.0, 102149155.0, 102382486.0, 102615813.0, 102849149.0, 103082474.0, 103315832.0, 103549134.0, 103782482.0, 103982472.0, 104215805.0, 104449137.0, 104682471.0, 104915799.0, 105149136.0, 105382468.0, 105615793.0, 105849117.0, 106049124.0, 106282449.0, 106515776.0, 106715785.0, 106949116.0, 107182448.0, 107415764.0, 107649095.0, 107882434.0, 108115758.0, 108349084.0, 108582419.0, 108815749.0, 109049081.0, 109282416.0, 109515746.0, 109749075.0, 109949080.0, 110182409.0, 110449070.0, 110649074.0, 110882428.0, 111115735.0, 111349063.0, 111549065.0, 111782398.0, 112015728.0, 112282388.0, 112515718.0, 112749047.0, 112949055.0, 113182384.0, 113449057.0, 60582822.0, 60849474.0, 61082806.0, 61316162.0, 61549464.0, 61749486.0, 61982804.0, 62216131.0, 62449470.0, 62682793.0, 62916121.0, 63116128.0, 63349460.0, 63582791.0, 63816116.0, 64016121.0, 64249472.0, 64482789.99999999, 64716106.0, 64949444.0, 65182767.0, 65416095.0, 65649432.00000001, 65882758.99999999, 66116086.99999999, 66349421.00000001, 66582829.00000001, 66849431.99999999, 67082766.00000001, 67316096.0, 67582755.0, 67782767.0, 68016093.0, 68249423.0, 68482746.0, 68716091.0, 68949420.0, 69182748.0, 69416070.0, 69616081.0, 69849411.0, 70082741.0, 70349401.0, 70582738.0, 70816067.0, 71016067.0, 71249399.0, 71482721.0, 71716069.0, 71949399.0, 72216067.0, 72482714.0, 72716061.0, 72949406.0, 73149383.0, 73382713.0, 73649375.0, 73882714.0, 74149368.0, 74349374.0, 74582713.0, 74849368.0, 75082704.0, 75316029.0, 75549355.0, 75816027.0, 76049354.0, 76282685.0, 76549347.0, 76749356.0, 77016019.0, 77249352.0, 77516007.0, 77716014.0, 77949344.0, 78149345.0, 78382680.0, 78616008.0, 78849330.0, 79082666.0, 79316008.0, 79549334.0, 79782666.0, 80049322.0, 80249343.0, 80482671.0, 80749322.0, 80982655.0, 81215978.0, 81449324.0, 81715974.0, 81915980.0, 82149308.0, 82415970.0, 82615978.0, 82882636.0, 83115963.0, 83349296.0, 83549303.0, 83749299.0, 83982634.0, 84215967.0, 84449293.0, 84649296.0, 84882627.0, 85115956.0, 85349288.0, 85549284.0, 85782616.0, 86015974.0, 86249290.0, 86482617.0, 86682611.0, 86915940.0, 87149268.0, 87382599.0, 87615937.0, 87849266.0, 88049267.0, 88282598.0, 88515921.0, 88749255.0, 88982608.0, 89215917.0, 89449255.0, 89649257.0, 89882587.0, 90115924.0, 90349255.0, 90582579.0, 90815914.0, 91049241.0, 91282568.0, 91515901.0, 91715908.0, 91949236.0, 92182569.0, 92415908.0, 92615903.0, 92849241.0, 93082557.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load x y from the csv file\n",
    "points3D_World = np.genfromtxt('output.csv', delimiter=',', skip_header=1, usecols=(3, 4, 5)) # (x, y, z) : (N, 3)\n",
    "\n",
    "input_3d_points = torch.tensor(points3D_World, dtype=torch.float32)\n",
    "\n",
    "TXYZa = np.genfromtxt('output.csv', delimiter=',', skip_header=1, usecols=(0, 1, 2, 3), dtype=('U10', 'f8', 'f8', 'f8'))\n",
    "\n",
    "'''\n",
    "time_array = [100049163.0, 100282495.0, 100482507.0, 100715833.0, 100982494.0, 101215830.0, 101449184.0, 101682492.0, 101915820.0, 102149155.0, 102382486.0, 102615813.0, 102849149.0, 103082474.0, 103315832.0, 103549134.0, 103782482.0, 103982472.0, 104215805.0, 104449137.0, 104682471.0, 104915799.0, 105149136.0, 105382468.0, 105615793.0, 105849117.0, 106049124.0, 106282449.0, 106515776.0, 106715785.0, 106949116.0, 107182448.0, 107415764.0, 107649095.0, 107882434.0, 108115758.0, 108349084.0, 108582419.0, 108815749.0, 109049081.0, 109282416.0, 109515746.0, 109749075.0, 109949080.0, 110182409.0, 110449070.0, 110649074.0, 110882428.0, 111115735.0, 111349063.0, 111549065.0, 111782398.0, 112015728.0, 112282388.0, 112515718.0, 112749047.0, 112949055.0, 113182384.0, 113449057.0, 60582822.0, 60849474.0, 61082806.0, 61316162.0, 61549464.0, 61749486.0, 61982804.0, 62216131.0, 62449470.0, 62682793.0, 62916121.0, 63116128.0, 63349460.0, 63582791.0, 63816116.0, 64016121.0, 64249472.0, 64482789.99999999, 64716106.0, 64949444.0, 65182767.0, 65416095.0, 65649432.00000001, 65882758.99999999, 66116086.99999999, 66349421.00000001, 66582829.00000001, 66849431.99999999, 67082766.00000001, 67316096.0, 67582755.0, 67782767.0, 68016093.0, 68249423.0, 68482746.0, 68716091.0, 68949420.0, 69182748.0, 69416070.0, 69616081.0, 69849411.0, 70082741.0, 70349401.0, 70582738.0, 70816067.0, 71016067.0, 71249399.0, 71482721.0, 71716069.0, 71949399.0, 72216067.0, 72482714.0, 72716061.0, 72949406.0, 73149383.0, 73382713.0, 73649375.0, 73882714.0, 74149368.0, 74349374.0, 74582713.0, 74849368.0, 75082704.0, 75316029.0, 75549355.0, 75816027.0, 76049354.0, 76282685.0, 76549347.0, 76749356.0, 77016019.0, 77249352.0, 77516007.0, 77716014.0, 77949344.0, 78149345.0, 78382680.0, 78616008.0, 78849330.0, 79082666.0, 79316008.0, 79549334.0, 79782666.0, 80049322.0, 80249343.0, 80482671.0, 80749322.0, 80982655.0, 81215978.0, 81449324.0, 81715974.0, 81915980.0, 82149308.0, 82415970.0, 82615978.0, 82882636.0, 83115963.0, 83349296.0, 83549303.0, 83749299.0, 83982634.0, 84215967.0, 84449293.0, 84649296.0, 84882627.0, 85115956.0, 85349288.0, 85549284.0, 85782616.0, 86015974.0, 86249290.0, 86482617.0, 86682611.0, 86915940.0, 87149268.0, 87382599.0, 87615937.0, 87849266.0, 88049267.0, 88282598.0, 88515921.0, 88749255.0, 88982608.0, 89215917.0, 89449255.0, 89649257.0, 89882587.0, 90115924.0, 90349255.0, 90582579.0, 90815914.0, 91049241.0, 91282568.0, 91515901.0, 91715908.0, 91949236.0, 92182569.0, 92415908.0, 92615903.0, 92849241.0, 93082557.0]\n",
    "Now need to sort the TXYZ array by time_array\n",
    "\n",
    "TXYZ snippet : [('100049163.', 226., 156.,  3.5) ('100282495.', 231., 155.,  3.5)\n",
    " ('100482507.', 231., 156.,  3.5) ('100715833.', 227., 157.,  3.5)\n",
    "\n",
    "'''\n",
    "\n",
    "time_arrays = [100049163.0, 100282495.0, 100482507.0, 100715833.0, 100982494.0, 101215830.0, 101449184.0, 101682492.0, 101915820.0, 102149155.0, 102382486.0, 102615813.0, 102849149.0, 103082474.0, 103315832.0, 103549134.0, 103782482.0, 103982472.0, 104215805.0, 104449137.0, 104682471.0, 104915799.0, 105149136.0, 105382468.0, 105615793.0, 105849117.0, 106049124.0, 106282449.0, 106515776.0, 106715785.0, 106949116.0, 107182448.0, 107415764.0, 107649095.0, 107882434.0, 108115758.0, 108349084.0, 108582419.0, 108815749.0, 109049081.0, 109282416.0, 109515746.0, 109749075.0, 109949080.0, 110182409.0, 110449070.0, 110649074.0, 110882428.0, 111115735.0, 111349063.0, 111549065.0, 111782398.0, 112015728.0, 112282388.0, 112515718.0, 112749047.0, 112949055.0, 113182384.0, 113449057.0, 60582822.0, 60849474.0, 61082806.0, 61316162.0, 61549464.0, 61749486.0, 61982804.0, 62216131.0, 62449470.0, 62682793.0, 62916121.0, 63116128.0, 63349460.0, 63582791.0, 63816116.0, 64016121.0, 64249472.0, 64482789.99999999, 64716106.0, 64949444.0, 65182767.0, 65416095.0, 65649432.00000001, 65882758.99999999, 66116086.99999999, 66349421.00000001, 66582829.00000001, 66849431.99999999, 67082766.00000001, 67316096.0, 67582755.0, 67782767.0, 68016093.0, 68249423.0, 68482746.0, 68716091.0, 68949420.0, 69182748.0, 69416070.0, 69616081.0, 69849411.0, 70082741.0, 70349401.0, 70582738.0, 70816067.0, 71016067.0, 71249399.0, 71482721.0, 71716069.0, 71949399.0, 72216067.0, 72482714.0, 72716061.0, 72949406.0, 73149383.0, 73382713.0, 73649375.0, 73882714.0, 74149368.0, 74349374.0, 74582713.0, 74849368.0, 75082704.0, 75316029.0, 75549355.0, 75816027.0, 76049354.0, 76282685.0, 76549347.0, 76749356.0, 77016019.0, 77249352.0, 77516007.0, 77716014.0, 77949344.0, 78149345.0, 78382680.0, 78616008.0, 78849330.0, 79082666.0, 79316008.0, 79549334.0, 79782666.0, 80049322.0, 80249343.0, 80482671.0, 80749322.0, 80982655.0, 81215978.0, 81449324.0, 81715974.0, 81915980.0, 82149308.0, 82415970.0, 82615978.0, 82882636.0, 83115963.0, 83349296.0, 83549303.0, 83749299.0, 83982634.0, 84215967.0, 84449293.0, 84649296.0, 84882627.0, 85115956.0, 85349288.0, 85549284.0, 85782616.0, 86015974.0, 86249290.0, 86482617.0, 86682611.0, 86915940.0, 87149268.0, 87382599.0, 87615937.0, 87849266.0, 88049267.0, 88282598.0, 88515921.0, 88749255.0, 88982608.0, 89215917.0, 89449255.0, 89649257.0, 89882587.0, 90115924.0, 90349255.0, 90582579.0, 90815914.0, 91049241.0, 91282568.0, 91515901.0, 91715908.0, 91949236.0, 92182569.0, 92415908.0, 92615903.0, 92849241.0, 93082557.0]\n",
    "\n",
    "# Make TXYZ_nontuple\n",
    "TXYZ_nontuple = []\n",
    "for i in range(len(TXYZa)):\n",
    "    TXYZ_nontuple.append([TXYZa[i][0], TXYZa[i][1], TXYZa[i][2], TXYZa[i][3]])\n",
    "# Remove 'j' from t of TXYZ, not all have a j\n",
    "for i in range(len(TXYZ_nontuple)):\n",
    "    if 'j' in TXYZ_nontuple[i][0]:\n",
    "        TXYZ_nontuple[i][0] = TXYZ_nontuple[i][0][:-1]\n",
    "\n",
    "print(TXYZ_nontuple)\n",
    "print(time_arrays)\n",
    "\n",
    "# Sort TXYZ by time_arrays\n",
    "TXYZ = sorted(TXYZ_nontuple, key=lambda x: x[0])\n",
    "\n",
    "\n",
    "# Load x y from the csv file\n",
    "points2D = np.genfromtxt('output.csv', delimiter=',', skip_header=1, usecols=(1, 2)) # (x, y) : (N, 2)\n",
    "img_width = 240\n",
    "img_height = 520\n",
    "\n",
    "# Normalise the points\n",
    "points2D[:, 0] = points2D[:, 0] / img_width\n",
    "points2D[:, 1] = points2D[:, 1] / img_height\n",
    "\n",
    "target_2d_points = torch.tensor(points2D, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss:  146.2172393798828\n",
      "Epoch [1/250], Loss: 146.2172393798828\n",
      "New best parameters found\n",
      "Epoch [2/250], Loss: 142.40196228027344\n",
      "New best parameters found\n",
      "Epoch [3/250], Loss: 138.70509338378906\n",
      "New best parameters found\n",
      "Epoch [4/250], Loss: 134.6456756591797\n",
      "New best parameters found\n",
      "Epoch [5/250], Loss: 129.9208526611328\n",
      "New best parameters found\n",
      "Epoch [6/250], Loss: 124.50846862792969\n",
      "New best parameters found\n",
      "Epoch [7/250], Loss: 118.10333251953125\n",
      "New best parameters found\n",
      "Epoch [8/250], Loss: 110.78356170654297\n",
      "New best parameters found\n",
      "Epoch [9/250], Loss: 102.59413146972656\n",
      "New best parameters found\n",
      "Epoch [10/250], Loss: 93.44254302978516\n",
      "New best parameters found\n",
      "Epoch [11/250], Loss: 83.46546173095703\n",
      "New best parameters found\n",
      "Epoch [12/250], Loss: 73.01664733886719\n",
      "New best parameters found\n",
      "Epoch [13/250], Loss: 62.431888580322266\n",
      "New best parameters found\n",
      "Epoch [14/250], Loss: 52.219852447509766\n",
      "New best parameters found\n",
      "Epoch [15/250], Loss: 43.46723937988281\n",
      "New best parameters found\n",
      "Epoch [16/250], Loss: 37.39332962036133\n",
      "New best parameters found\n",
      "Epoch [17/250], Loss: 35.34197235107422\n",
      "Epoch [18/250], Loss: 38.09754943847656\n",
      "Epoch [19/250], Loss: 43.38992691040039\n",
      "Epoch    20: reducing learning rate of group 0 to 1.3500e-02.\n",
      "Epoch [20/250], Loss: 47.28730392456055\n",
      "Epoch [21/250], Loss: 47.603511810302734\n",
      "Epoch [22/250], Loss: 45.17588424682617\n",
      "Epoch    23: reducing learning rate of group 0 to 1.2150e-02.\n",
      "Epoch [23/250], Loss: 41.464508056640625\n",
      "Epoch [24/250], Loss: 37.79192352294922\n",
      "New best parameters found\n",
      "Epoch [25/250], Loss: 35.25776672363281\n",
      "New best parameters found\n",
      "Epoch [26/250], Loss: 33.67023849487305\n",
      "New best parameters found\n",
      "Epoch [27/250], Loss: 33.03728485107422\n",
      "Epoch [28/250], Loss: 33.162322998046875\n",
      "Epoch [29/250], Loss: 33.74575424194336\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0935e-02.\n",
      "Epoch [30/250], Loss: 34.47950744628906\n",
      "Epoch [31/250], Loss: 35.144439697265625\n",
      "Epoch [32/250], Loss: 35.54951858520508\n",
      "Epoch    33: reducing learning rate of group 0 to 9.8415e-03.\n",
      "Epoch [33/250], Loss: 35.70382308959961\n",
      "Epoch [34/250], Loss: 35.619964599609375\n",
      "Epoch [35/250], Loss: 35.36005401611328\n",
      "Epoch    36: reducing learning rate of group 0 to 8.8574e-03.\n",
      "Epoch [36/250], Loss: 34.961299896240234\n",
      "Epoch [37/250], Loss: 34.47893142700195\n",
      "Epoch [38/250], Loss: 34.01837158203125\n",
      "Epoch    39: reducing learning rate of group 0 to 7.9716e-03.\n",
      "Epoch [39/250], Loss: 33.574485778808594\n",
      "Epoch [40/250], Loss: 33.186458587646484\n",
      "New best parameters found\n",
      "Epoch [41/250], Loss: 32.90934753417969\n",
      "New best parameters found\n",
      "Epoch [42/250], Loss: 32.713932037353516\n",
      "New best parameters found\n",
      "Epoch [43/250], Loss: 32.603553771972656\n",
      "New best parameters found\n",
      "Epoch [44/250], Loss: 32.57107925415039\n",
      "Epoch [45/250], Loss: 32.6000862121582\n",
      "Epoch [46/250], Loss: 32.667789459228516\n",
      "Epoch    47: reducing learning rate of group 0 to 7.1745e-03.\n",
      "Epoch [47/250], Loss: 32.74867248535156\n",
      "Epoch [48/250], Loss: 32.8194465637207\n",
      "Epoch [49/250], Loss: 32.85478210449219\n",
      "Epoch    50: reducing learning rate of group 0 to 6.4570e-03.\n",
      "Epoch [50/250], Loss: 32.85596466064453\n",
      "Epoch [51/250], Loss: 32.821533203125\n",
      "Epoch [52/250], Loss: 32.76332473754883\n",
      "Epoch    53: reducing learning rate of group 0 to 5.8113e-03.\n",
      "Epoch [53/250], Loss: 32.68593978881836\n",
      "Epoch [54/250], Loss: 32.59904098510742\n",
      "New best parameters found\n",
      "Epoch [55/250], Loss: 32.520137786865234\n",
      "New best parameters found\n",
      "Epoch [56/250], Loss: 32.446678161621094\n",
      "New best parameters found\n",
      "Epoch [57/250], Loss: 32.38362121582031\n",
      "New best parameters found\n",
      "Epoch [58/250], Loss: 32.333797454833984\n",
      "New best parameters found\n",
      "Epoch [59/250], Loss: 32.29800033569336\n",
      "New best parameters found\n",
      "Epoch [60/250], Loss: 32.275455474853516\n",
      "New best parameters found\n",
      "Epoch [61/250], Loss: 32.26394271850586\n",
      "New best parameters found\n",
      "Epoch [62/250], Loss: 32.260398864746094\n",
      "Epoch [63/250], Loss: 32.26169204711914\n",
      "Epoch [64/250], Loss: 32.26468276977539\n",
      "Epoch    65: reducing learning rate of group 0 to 5.2302e-03.\n",
      "Epoch [65/250], Loss: 32.26667404174805\n",
      "Epoch [66/250], Loss: 32.265655517578125\n",
      "Epoch [67/250], Loss: 32.260963439941406\n",
      "New best parameters found\n",
      "Epoch [68/250], Loss: 32.25210189819336\n",
      "New best parameters found\n",
      "Epoch [69/250], Loss: 32.23908233642578\n",
      "New best parameters found\n",
      "Epoch [70/250], Loss: 32.22114944458008\n",
      "New best parameters found\n",
      "Epoch [71/250], Loss: 32.20074462890625\n",
      "New best parameters found\n",
      "Epoch [72/250], Loss: 32.17967987060547\n",
      "New best parameters found\n",
      "Epoch [73/250], Loss: 32.15936279296875\n",
      "New best parameters found\n",
      "Epoch [74/250], Loss: 32.141048431396484\n",
      "New best parameters found\n",
      "Epoch [75/250], Loss: 32.12542724609375\n",
      "New best parameters found\n",
      "Epoch [76/250], Loss: 32.112831115722656\n",
      "New best parameters found\n",
      "Epoch [77/250], Loss: 32.10297393798828\n",
      "New best parameters found\n",
      "Epoch [78/250], Loss: 32.09510803222656\n",
      "New best parameters found\n",
      "Epoch [79/250], Loss: 32.08845520019531\n",
      "New best parameters found\n",
      "Epoch [80/250], Loss: 32.081974029541016\n",
      "New best parameters found\n",
      "Epoch [81/250], Loss: 32.075008392333984\n",
      "New best parameters found\n",
      "Epoch [82/250], Loss: 32.06709289550781\n",
      "New best parameters found\n",
      "Epoch [83/250], Loss: 32.05818176269531\n",
      "New best parameters found\n",
      "Epoch [84/250], Loss: 32.04847717285156\n",
      "New best parameters found\n",
      "Epoch [85/250], Loss: 32.038326263427734\n",
      "New best parameters found\n",
      "Epoch [86/250], Loss: 32.02804946899414\n",
      "New best parameters found\n",
      "Epoch [87/250], Loss: 32.01808547973633\n",
      "New best parameters found\n",
      "Epoch [88/250], Loss: 32.00871658325195\n",
      "New best parameters found\n",
      "Epoch [89/250], Loss: 32.00004196166992\n",
      "New best parameters found\n",
      "Epoch [90/250], Loss: 31.9921817779541\n",
      "New best parameters found\n",
      "Epoch [91/250], Loss: 31.984912872314453\n",
      "New best parameters found\n",
      "Epoch [92/250], Loss: 31.978179931640625\n",
      "New best parameters found\n",
      "Epoch [93/250], Loss: 31.971708297729492\n",
      "New best parameters found\n",
      "Epoch [94/250], Loss: 31.965316772460938\n",
      "New best parameters found\n",
      "Epoch [95/250], Loss: 31.95884895324707\n",
      "New best parameters found\n",
      "Epoch [96/250], Loss: 31.952192306518555\n",
      "New best parameters found\n",
      "Epoch [97/250], Loss: 31.945371627807617\n",
      "New best parameters found\n",
      "Epoch [98/250], Loss: 31.938417434692383\n",
      "New best parameters found\n",
      "Epoch [99/250], Loss: 31.931442260742188\n",
      "New best parameters found\n",
      "Epoch [100/250], Loss: 31.924489974975586\n",
      "New best parameters found\n",
      "Epoch [101/250], Loss: 31.917726516723633\n",
      "New best parameters found\n",
      "Epoch [102/250], Loss: 31.911182403564453\n",
      "New best parameters found\n",
      "Epoch [103/250], Loss: 31.90497589111328\n",
      "New best parameters found\n",
      "Epoch [104/250], Loss: 31.899003982543945\n",
      "New best parameters found\n",
      "Epoch [105/250], Loss: 31.893251419067383\n",
      "New best parameters found\n",
      "Epoch [106/250], Loss: 31.88775062561035\n",
      "New best parameters found\n",
      "Epoch [107/250], Loss: 31.88241958618164\n",
      "New best parameters found\n",
      "Epoch [108/250], Loss: 31.877140045166016\n",
      "New best parameters found\n",
      "Epoch [109/250], Loss: 31.871906280517578\n",
      "New best parameters found\n",
      "Epoch [110/250], Loss: 31.866674423217773\n",
      "New best parameters found\n",
      "Epoch [111/250], Loss: 31.861446380615234\n",
      "New best parameters found\n",
      "Epoch [112/250], Loss: 31.856306076049805\n",
      "New best parameters found\n",
      "Epoch [113/250], Loss: 31.851160049438477\n",
      "New best parameters found\n",
      "Epoch [114/250], Loss: 31.846168518066406\n",
      "New best parameters found\n",
      "Epoch [115/250], Loss: 31.84131622314453\n",
      "New best parameters found\n",
      "Epoch [116/250], Loss: 31.83658790588379\n",
      "New best parameters found\n",
      "Epoch [117/250], Loss: 31.83198356628418\n",
      "New best parameters found\n",
      "Epoch [118/250], Loss: 31.827524185180664\n",
      "New best parameters found\n",
      "Epoch [119/250], Loss: 31.823179244995117\n",
      "New best parameters found\n",
      "Epoch [120/250], Loss: 31.818988800048828\n",
      "New best parameters found\n",
      "Epoch [121/250], Loss: 31.81480598449707\n",
      "New best parameters found\n",
      "Epoch [122/250], Loss: 31.81072235107422\n",
      "New best parameters found\n",
      "Epoch [123/250], Loss: 31.80670166015625\n",
      "New best parameters found\n",
      "Epoch [124/250], Loss: 31.802703857421875\n",
      "New best parameters found\n",
      "Epoch [125/250], Loss: 31.798776626586914\n",
      "New best parameters found\n",
      "Epoch [126/250], Loss: 31.79489517211914\n",
      "New best parameters found\n",
      "Epoch [127/250], Loss: 31.79112434387207\n",
      "New best parameters found\n",
      "Epoch [128/250], Loss: 31.78738021850586\n",
      "New best parameters found\n",
      "Epoch [129/250], Loss: 31.783742904663086\n",
      "New best parameters found\n",
      "Epoch [130/250], Loss: 31.780208587646484\n",
      "New best parameters found\n",
      "Epoch [131/250], Loss: 31.77672576904297\n",
      "New best parameters found\n",
      "Epoch [132/250], Loss: 31.773252487182617\n",
      "New best parameters found\n",
      "Epoch [133/250], Loss: 31.76988410949707\n",
      "New best parameters found\n",
      "Epoch [134/250], Loss: 31.76658058166504\n",
      "New best parameters found\n",
      "Epoch [135/250], Loss: 31.763324737548828\n",
      "New best parameters found\n",
      "Epoch [136/250], Loss: 31.760141372680664\n",
      "New best parameters found\n",
      "Epoch [137/250], Loss: 31.756946563720703\n",
      "New best parameters found\n",
      "Epoch [138/250], Loss: 31.75381088256836\n",
      "New best parameters found\n",
      "Epoch [139/250], Loss: 31.750734329223633\n",
      "New best parameters found\n",
      "Epoch [140/250], Loss: 31.74773597717285\n",
      "New best parameters found\n",
      "Epoch [141/250], Loss: 31.74471664428711\n",
      "New best parameters found\n",
      "Epoch [142/250], Loss: 31.741809844970703\n",
      "New best parameters found\n",
      "Epoch [143/250], Loss: 31.73889923095703\n",
      "New best parameters found\n",
      "Epoch [144/250], Loss: 31.736040115356445\n",
      "New best parameters found\n",
      "Epoch [145/250], Loss: 31.733219146728516\n",
      "New best parameters found\n",
      "Epoch [146/250], Loss: 31.7304744720459\n",
      "New best parameters found\n",
      "Epoch [147/250], Loss: 31.727678298950195\n",
      "New best parameters found\n",
      "Epoch [148/250], Loss: 31.72496795654297\n",
      "New best parameters found\n",
      "Epoch [149/250], Loss: 31.722244262695312\n",
      "New best parameters found\n",
      "Epoch [150/250], Loss: 31.719589233398438\n",
      "New best parameters found\n",
      "Epoch [151/250], Loss: 31.7169246673584\n",
      "New best parameters found\n",
      "Epoch [152/250], Loss: 31.71429443359375\n",
      "New best parameters found\n",
      "Epoch [153/250], Loss: 31.71170997619629\n",
      "New best parameters found\n",
      "Epoch [154/250], Loss: 31.709144592285156\n",
      "New best parameters found\n",
      "Epoch [155/250], Loss: 31.70657730102539\n",
      "New best parameters found\n",
      "Epoch [156/250], Loss: 31.704055786132812\n",
      "New best parameters found\n",
      "Epoch [157/250], Loss: 31.701541900634766\n",
      "New best parameters found\n",
      "Epoch [158/250], Loss: 31.699007034301758\n",
      "New best parameters found\n",
      "Epoch [159/250], Loss: 31.696516036987305\n",
      "New best parameters found\n",
      "Epoch [160/250], Loss: 31.694063186645508\n",
      "New best parameters found\n",
      "Epoch [161/250], Loss: 31.691598892211914\n",
      "New best parameters found\n",
      "Epoch [162/250], Loss: 31.68916130065918\n",
      "New best parameters found\n",
      "Epoch [163/250], Loss: 31.686704635620117\n",
      "New best parameters found\n",
      "Epoch [164/250], Loss: 31.684295654296875\n",
      "New best parameters found\n",
      "Epoch [165/250], Loss: 31.68185043334961\n",
      "New best parameters found\n",
      "Epoch [166/250], Loss: 31.679466247558594\n",
      "New best parameters found\n",
      "Epoch [167/250], Loss: 31.67708396911621\n",
      "New best parameters found\n",
      "Epoch [168/250], Loss: 31.674673080444336\n",
      "New best parameters found\n",
      "Epoch [169/250], Loss: 31.672290802001953\n",
      "New best parameters found\n",
      "Epoch [170/250], Loss: 31.669897079467773\n",
      "New best parameters found\n",
      "Epoch [171/250], Loss: 31.66753387451172\n",
      "New best parameters found\n",
      "Epoch [172/250], Loss: 31.665128707885742\n",
      "New best parameters found\n",
      "Epoch [173/250], Loss: 31.66277313232422\n",
      "New best parameters found\n",
      "Epoch [174/250], Loss: 31.660358428955078\n",
      "New best parameters found\n",
      "Epoch [175/250], Loss: 31.658000946044922\n",
      "New best parameters found\n",
      "Epoch [176/250], Loss: 31.655664443969727\n",
      "New best parameters found\n",
      "Epoch [177/250], Loss: 31.653268814086914\n",
      "New best parameters found\n",
      "Epoch [178/250], Loss: 31.65088653564453\n",
      "New best parameters found\n",
      "Epoch [179/250], Loss: 31.648542404174805\n",
      "New best parameters found\n",
      "Epoch [180/250], Loss: 31.646163940429688\n",
      "New best parameters found\n",
      "Epoch [181/250], Loss: 31.643796920776367\n",
      "New best parameters found\n",
      "Epoch [182/250], Loss: 31.64141082763672\n",
      "New best parameters found\n",
      "Epoch [183/250], Loss: 31.6390323638916\n",
      "New best parameters found\n",
      "Epoch [184/250], Loss: 31.636625289916992\n",
      "New best parameters found\n",
      "Epoch [185/250], Loss: 31.6342716217041\n",
      "New best parameters found\n",
      "Epoch [186/250], Loss: 31.631872177124023\n",
      "New best parameters found\n",
      "Epoch [187/250], Loss: 31.629491806030273\n",
      "New best parameters found\n",
      "Epoch [188/250], Loss: 31.62704086303711\n",
      "New best parameters found\n",
      "Epoch [189/250], Loss: 31.62467384338379\n",
      "New best parameters found\n",
      "Epoch [190/250], Loss: 31.622241973876953\n",
      "New best parameters found\n",
      "Epoch [191/250], Loss: 31.61981964111328\n",
      "New best parameters found\n",
      "Epoch [192/250], Loss: 31.617429733276367\n",
      "New best parameters found\n",
      "Epoch [193/250], Loss: 31.614974975585938\n",
      "New best parameters found\n",
      "Epoch [194/250], Loss: 31.612524032592773\n",
      "New best parameters found\n",
      "Epoch [195/250], Loss: 31.610074996948242\n",
      "New best parameters found\n",
      "Epoch [196/250], Loss: 31.60764503479004\n",
      "New best parameters found\n",
      "Epoch [197/250], Loss: 31.605140686035156\n",
      "New best parameters found\n",
      "Epoch [198/250], Loss: 31.60268783569336\n",
      "New best parameters found\n",
      "Epoch [199/250], Loss: 31.600215911865234\n",
      "New best parameters found\n",
      "Epoch [200/250], Loss: 31.597700119018555\n",
      "New best parameters found\n",
      "Epoch [201/250], Loss: 31.595205307006836\n",
      "New best parameters found\n",
      "Epoch [202/250], Loss: 31.592693328857422\n",
      "New best parameters found\n",
      "Epoch [203/250], Loss: 31.590150833129883\n",
      "New best parameters found\n",
      "Epoch [204/250], Loss: 31.587604522705078\n",
      "New best parameters found\n",
      "Epoch [205/250], Loss: 31.58504295349121\n",
      "New best parameters found\n",
      "Epoch [206/250], Loss: 31.582494735717773\n",
      "New best parameters found\n",
      "Epoch [207/250], Loss: 31.579931259155273\n",
      "New best parameters found\n",
      "Epoch [208/250], Loss: 31.577346801757812\n",
      "New best parameters found\n",
      "Epoch [209/250], Loss: 31.57473373413086\n",
      "New best parameters found\n",
      "Epoch [210/250], Loss: 31.5721435546875\n",
      "New best parameters found\n",
      "Epoch [211/250], Loss: 31.56948471069336\n",
      "New best parameters found\n",
      "Epoch [212/250], Loss: 31.566858291625977\n",
      "New best parameters found\n",
      "Epoch [213/250], Loss: 31.564186096191406\n",
      "New best parameters found\n",
      "Epoch [214/250], Loss: 31.561519622802734\n",
      "New best parameters found\n",
      "Epoch [215/250], Loss: 31.558822631835938\n",
      "New best parameters found\n",
      "Epoch [216/250], Loss: 31.5561466217041\n",
      "New best parameters found\n",
      "Epoch [217/250], Loss: 31.55340576171875\n",
      "New best parameters found\n",
      "Epoch [218/250], Loss: 31.5506591796875\n",
      "New best parameters found\n",
      "Epoch [219/250], Loss: 31.547893524169922\n",
      "New best parameters found\n",
      "Epoch [220/250], Loss: 31.545122146606445\n",
      "New best parameters found\n",
      "Epoch [221/250], Loss: 31.54232406616211\n",
      "New best parameters found\n",
      "Epoch [222/250], Loss: 31.5395450592041\n",
      "New best parameters found\n",
      "Epoch [223/250], Loss: 31.536598205566406\n",
      "New best parameters found\n",
      "Epoch [224/250], Loss: 31.53373146057129\n",
      "New best parameters found\n",
      "Epoch [225/250], Loss: 31.530771255493164\n",
      "New best parameters found\n",
      "Epoch [226/250], Loss: 31.527748107910156\n",
      "New best parameters found\n",
      "Epoch [227/250], Loss: 31.52471160888672\n",
      "New best parameters found\n",
      "Epoch [228/250], Loss: 31.52168083190918\n",
      "New best parameters found\n",
      "Epoch [229/250], Loss: 31.518600463867188\n",
      "New best parameters found\n",
      "Epoch [230/250], Loss: 31.51547622680664\n",
      "New best parameters found\n",
      "Epoch [231/250], Loss: 31.51233673095703\n",
      "New best parameters found\n",
      "Epoch [232/250], Loss: 31.5091495513916\n",
      "New best parameters found\n",
      "Epoch [233/250], Loss: 31.50591278076172\n",
      "New best parameters found\n",
      "Epoch [234/250], Loss: 31.502656936645508\n",
      "New best parameters found\n",
      "Epoch [235/250], Loss: 31.499324798583984\n",
      "New best parameters found\n",
      "Epoch [236/250], Loss: 31.496013641357422\n",
      "New best parameters found\n",
      "Epoch [237/250], Loss: 31.49260139465332\n",
      "New best parameters found\n",
      "Epoch [238/250], Loss: 31.489185333251953\n",
      "New best parameters found\n",
      "Epoch [239/250], Loss: 31.485719680786133\n",
      "New best parameters found\n",
      "Epoch [240/250], Loss: 31.48216438293457\n",
      "New best parameters found\n",
      "Epoch [241/250], Loss: 31.47864532470703\n",
      "New best parameters found\n",
      "Epoch [242/250], Loss: 31.47499656677246\n",
      "New best parameters found\n",
      "Epoch [243/250], Loss: 31.47136688232422\n",
      "New best parameters found\n",
      "Epoch [244/250], Loss: 31.467666625976562\n",
      "New best parameters found\n",
      "Epoch [245/250], Loss: 31.463911056518555\n",
      "New best parameters found\n",
      "Epoch [246/250], Loss: 31.460100173950195\n",
      "New best parameters found\n",
      "Epoch [247/250], Loss: 31.45628547668457\n",
      "New best parameters found\n",
      "Epoch [248/250], Loss: 31.452394485473633\n",
      "New best parameters found\n",
      "Epoch [249/250], Loss: 31.448421478271484\n",
      "New best parameters found\n",
      "Epoch [250/250], Loss: 31.444419860839844\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "\n",
    "# Make MSE loss function, takes in (x,y) pairs\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Create an instance of the model\n",
    "model = CameraParameterEstimator(initial_params)\n",
    "\n",
    "# Convert the model's parameters to Float type\n",
    "model = model.float()\n",
    "\n",
    "# Create an instance of the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.015, weight_decay=3e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=2, verbose=True)\n",
    "# Number of training steps is number of epochs times number of batches\n",
    "# Assuming one batch per epoch in this case\n",
    "num_training_steps = num_epochs\n",
    "\n",
    "# Number of warmup steps is typically 10% of total training steps\n",
    "num_warmup_steps = num_training_steps // 10\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "#scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
    "image_path = r\"C:\\Users\\Jonathan van Zyl\\Documents\\GitHub\\paparazzi\\COMPUTERVISIONSIM\\Projection\\Images\"\n",
    "loss_array = []\n",
    "loss_array_total = []\n",
    "predicted_parameters_best = initial_params\n",
    "time_array = []\n",
    "for epoch in range(num_epochs):        \n",
    "    # Forward pass: compute predicted parameters from input_3D_points\n",
    "    loss_array_epoch = []\n",
    "    loss = 0\n",
    "    for i in range(target_2d_points.shape[0]):\n",
    "        predicted_parameters = model(input_3d_points[i])\n",
    "        # Use the predicted parameters to compute predicted 2D points\n",
    "        # This involves applying the camera model equations using the predicted parameters\n",
    "        # For simplicity, let's assume a function 'apply_camera_model' that does this\n",
    "        #predicted_2d_points = apply_camera_model(predicted_parameters, input_3d_points)\n",
    "        # Use the predicted parameters to compute predicted 2D points\n",
    "        predicted_2d_points = []\n",
    "        points2d_temp, time = apply_camera_model(predicted_parameters, input_3d_points, i)\n",
    "        predicted_2d_points.append(points2d_temp)\n",
    "\n",
    "        # Check time\n",
    "        XYZ = input_3d_points[i].numpy()\n",
    "        time_array.append(time)\n",
    "\n",
    "        \n",
    "        # Convert predicted_2d_points to a tensor\n",
    "        predicted_2d_points_tensor = torch.stack(predicted_2d_points).float()\n",
    "\n",
    "        # Convert target_2d_points to a tensor and add an extra dimension\n",
    "        target_2d_points_tensor = target_2d_points[i].clone().detach().requires_grad_(True).unsqueeze(0)\n",
    "\n",
    "        # Compute loss between predicted 2D points and target 2D points\n",
    "        loss += loss_fn(predicted_2d_points_tensor, target_2d_points_tensor)/len(target_2d_points_tensor)\n",
    "        loss_array_epoch.append(loss.item())\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # Print the loss every 100 epochs\n",
    "    optimizer.step()\n",
    "    # Scheduler\n",
    "    scheduler.step(loss)\n",
    "    if epoch == 0:\n",
    "        print(\"Initial loss: \", loss.item())\n",
    "        predicted_parameters_best = predicted_parameters\n",
    "    elif loss.item() < min(loss_array):\n",
    "        predicted_parameters_best = predicted_parameters\n",
    "        print(\"New best parameters found\")\n",
    "\n",
    "    loss_array_total.append(loss_array_epoch)\n",
    "    loss_array.append(loss.item())\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "    if loss.item() < 0.015:\n",
    "        break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1942, 0.2588]], grad_fn=<StackBackward>) tensor([[0.8208, 0.3077]], grad_fn=<UnsqueezeBackward0>)\n",
      "Predicted parameters:  tensor([3.1618e+02, 4.0279e+02, 3.1997e+02, 2.8310e+02, 7.4057e+00, 1.1285e+01,\n",
      "        1.3633e+01, 2.0400e-06], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Plot the loss\n",
    "plt.plot(loss_array)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "print(predicted_2d_points_tensor, target_2d_points_tensor)\n",
    "\n",
    "print(\"Predicted parameters: \", predicted_parameters_best)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
