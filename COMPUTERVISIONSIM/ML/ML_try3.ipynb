{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jonathan van Zyl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_3d.shape: torch.Size([197, 3])\n",
      "target_2d.shape: torch.Size([197, 2])\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('points.csv')\n",
    "\n",
    "# Remove the 'tensor' prefix and convert to float\n",
    "data = data.applymap(lambda x: float(x.replace('tensor(', '').replace(')', '')))\n",
    "\n",
    "# Split the data into 3D and 2D points\n",
    "input_3d = data[['x_3d', 'y_3d', 'z_3d']].values\n",
    "target_2d = data[['x_2d', 'y_2d']].values\n",
    "\n",
    "# Convert to tensors\n",
    "input_3d = torch.tensor(input_3d, dtype=torch.float32)\n",
    "target_2d = torch.tensor(target_2d, dtype=torch.float32)\n",
    "\n",
    "# Print tensor shape\n",
    "print('input_3d.shape:', input_3d.shape)\n",
    "print('target_2d.shape:', target_2d.shape)\n",
    "# print warning if any nan or inf\n",
    "if torch.isnan(input_3d).any() or torch.isnan(target_2d).any() or torch.isinf(input_3d).any() or torch.isinf(target_2d).any():\n",
    "    print('Warning: nan or inf found in input_3d or target_2d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Camera Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_camera_model(predicted_params, points_3d):\n",
    "    \"\"\"\n",
    "    Apply the camera model to project 3D points to 2D using predicted camera parameters.\n",
    "    \n",
    "    :param predicted_params: Tensor containing the predicted camera parameters [f_x, f_y, c_x, c_y, k1, k2, k3, p_1, p_2]\n",
    "    :param points_3d: Tensor containing 3D points in camera coordinates, shape [N, 3]\n",
    "    :return: Tensor containing the projected 2D points, shape [N, 2]\n",
    "    \"\"\"\n",
    "    predicted_params = predicted_params.squeeze()\n",
    "\n",
    "    f_x, f_y, c_x, c_y, k1, k2, k3, p_1, p_2 = predicted_params\n",
    "\n",
    "    f_x =  f_x\n",
    "    f_y = f_y \n",
    "    c_x = c_x \n",
    "    c_y = c_y \n",
    "    #print(f_x, f_y, c_x, c_y, k1, k2, k3, p_1, p_2)\n",
    "\n",
    "    # Unpack K matrix\n",
    "    \n",
    "    # Normalize 3D points (X_c/Z_c, Y_c/Z_c)\n",
    "    X_c = points_3d[:, 0]\n",
    "    Y_c = points_3d[:, 1]\n",
    "    Z_c = points_3d[:, 2] + 1e-6\n",
    "    x_normalized = X_c / Z_c\n",
    "    y_normalized = Y_c / Z_c\n",
    "    \n",
    "    # Compute r^2 = x_normalized^2 + y_normalized^2\n",
    "    r_squared = x_normalized**2 + y_normalized**2\n",
    "    \n",
    "    # Apply radial distortion correction\n",
    "    radial_factor = 1 + k1 * r_squared + k2 * r_squared**2 + k3 * r_squared**3\n",
    "    x_radial = x_normalized * radial_factor\n",
    "    y_radial = y_normalized * radial_factor\n",
    "    \n",
    "    # Apply tangential distortion correction\n",
    "    x_tangential = 2 * p_1 * x_normalized * y_normalized + p_2 * (r_squared + 2 * x_normalized**2)\n",
    "    y_tangential = p_1 * (r_squared + 2 * y_normalized**2) + 2 * p_2 * x_normalized * y_normalized\n",
    "    \n",
    "    # Combine radial and tangential distortions\n",
    "    x_distorted = x_radial + x_tangential\n",
    "    y_distorted = y_radial + y_tangential\n",
    "    \n",
    "    # Convert distorted coordinates back to pixel coordinates\n",
    "    u = f_x * x_distorted + c_x\n",
    "    v = f_y * y_distorted + c_y\n",
    "    \n",
    "    # Stack the 2D points into a single tensor\n",
    "    points_2d = torch.stack([u, v], dim=-1)\n",
    "\n",
    "    img_width = 240\n",
    "    img_height = 520\n",
    "\n",
    "    # Normalise the points\n",
    "    points_2d[:, 0] = points_2d[:, 0] / img_width\n",
    "    points_2d[:, 1] = points_2d[:, 1] / img_height\n",
    "\n",
    "    \n",
    "    return points_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Predicted Parameters: tensor([[ 4.2576e+02,  2.7939e+02,  4.0960e+02,  ..., -6.3437e-01,\n",
      "         -4.3137e-01,  2.1490e-01],\n",
      "        [ 4.2635e+02,  2.8092e+02,  4.1316e+02,  ..., -6.2891e-01,\n",
      "         -4.3124e-01,  2.0730e-01],\n",
      "        [ 4.2666e+02,  2.8183e+02,  4.1561e+02,  ..., -6.2528e-01,\n",
      "         -4.3159e-01,  2.0228e-01],\n",
      "        ...,\n",
      "        [ 2.3313e+02,  1.4894e+02,  5.4689e+02,  ..., -3.3611e-01,\n",
      "         -2.3022e-01,  7.1777e-01],\n",
      "        [ 2.4413e+02,  1.5559e+02,  5.2744e+02,  ..., -3.8133e-01,\n",
      "         -2.3334e-01,  6.9938e-01],\n",
      "        [ 2.4951e+02,  1.5869e+02,  5.3910e+02,  ..., -3.5205e-01,\n",
      "         -2.2979e-01,  6.9266e-01]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "# Make neural network\n",
    "class CameraModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CameraModel, self).__init__()\n",
    "        # Input is 3D points, output is predicted params size 9\n",
    "        self.fc1 = nn.Linear(3, 9)\n",
    "        self.fc2 = nn.Linear(9, 9)\n",
    "\n",
    "        # initial guesses [500, 500, 300, 300, 0.01, 0.01, 0.01, 0.01, 0.01] of output change bias\n",
    "        #self.fc1.bias.data = torch.tensor([500, 500, 300, 300, 0.01, 0.01, 0.01, 0.01, 0.01], dtype=torch.float32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # First 4 outputs between 0 and 1000\n",
    "        x[:, 0] = torch.sigmoid(x[:, 0]) * 1000\n",
    "        x[:, 1] = torch.sigmoid(x[:, 1]) * 1000\n",
    "        x[:, 2] = torch.sigmoid(x[:, 2]) * 1000\n",
    "        x[:, 3] = torch.sigmoid(x[:, 3]) * 1000\n",
    "\n",
    "        # Last 5 outputs between -1 and 1\n",
    "        x[:, 4] = torch.tanh(x[:, 4])\n",
    "        x[:, 5] = torch.tanh(x[:, 5])\n",
    "        x[:, 6] = torch.tanh(x[:, 6])\n",
    "        x[:, 7] = torch.tanh(x[:, 7])\n",
    "        x[:, 8] = torch.tanh(x[:, 8])\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Create the model\n",
    "model = CameraModel()\n",
    "# After model initialization, check the initial predictions\n",
    "initial_pred_params = model(input_3d)\n",
    "print(\"Initial Predicted Parameters:\", initial_pred_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights and Biases:\n",
      "fc1.weight tensor([[ 0.3998, -0.2866,  0.3898],\n",
      "        [-0.1662,  0.0182,  0.3792],\n",
      "        [-0.5714,  0.0038,  0.0243],\n",
      "        [ 0.3180,  0.2138, -0.1072],\n",
      "        [ 0.2047, -0.1865, -0.0146],\n",
      "        [-0.4077, -0.0153,  0.2559],\n",
      "        [ 0.3794,  0.3467,  0.3448],\n",
      "        [ 0.1361, -0.0402,  0.2228],\n",
      "        [-0.2950,  0.0619, -0.5731]])\n",
      "fc1.bias tensor([-0.4851,  0.0483, -0.5558,  0.1374, -0.0189, -0.5002,  0.2897, -0.4367,\n",
      "        -0.2480])\n",
      "fc2.weight tensor([[-0.2944, -0.0159,  0.0388,  0.3086,  0.1204,  0.0346, -0.2327, -0.2463,\n",
      "          0.0847],\n",
      "        [-0.2147, -0.3289,  0.0657,  0.2757, -0.2158, -0.2080, -0.3190,  0.1232,\n",
      "         -0.1537],\n",
      "        [ 0.0015,  0.0793, -0.0657,  0.1321,  0.2011,  0.2203, -0.2893,  0.3308,\n",
      "         -0.0745],\n",
      "        [-0.1420,  0.0158,  0.2514, -0.3319, -0.2378, -0.1294, -0.3252,  0.3045,\n",
      "          0.2267],\n",
      "        [ 0.1668, -0.1102,  0.2499,  0.1753, -0.0994, -0.0689,  0.3255, -0.2859,\n",
      "          0.0018],\n",
      "        [ 0.0731, -0.1704,  0.1080,  0.2004, -0.0562, -0.0478, -0.3099, -0.2319,\n",
      "         -0.2864],\n",
      "        [ 0.2884, -0.0589,  0.1426,  0.1653, -0.2062,  0.1924, -0.2427, -0.2269,\n",
      "          0.1966],\n",
      "        [ 0.0485, -0.2154,  0.2234,  0.2185, -0.1322,  0.2960, -0.1631,  0.1357,\n",
      "          0.0417],\n",
      "        [ 0.2172,  0.1153,  0.2752, -0.0966,  0.1375,  0.3043,  0.1885, -0.2570,\n",
      "          0.3103]])\n",
      "fc2.bias tensor([-0.0789, -0.2960,  0.3049,  0.2061,  0.0991, -0.0856, -0.2384, -0.2452,\n",
      "        -0.2545])\n",
      " predicted params mean tensor([ 4.3174e+02,  2.7881e+02,  5.0438e+02,  3.1481e+02,  6.7927e-01,\n",
      "        -4.7283e-01, -3.1693e-01, -2.3086e-01,  3.1951e-01],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "predicted_2d.shape: torch.Size([197, 2])\n",
      "target_2d.shape: torch.Size([197, 2])\n",
      "Model Weights and Biases:\n",
      "fc1.weight tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]])\n",
      "fc1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "fc2.weight tensor([[    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan],\n",
      "        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan],\n",
      "        [ 0.0015,  0.0793, -0.0657,  0.1321,  0.2011,  0.2203, -0.2893,  0.3308,\n",
      "         -0.0745],\n",
      "        [-0.1420,  0.0158,  0.2514, -0.3319, -0.2378, -0.1294, -0.3252,  0.3045,\n",
      "          0.2267],\n",
      "        [ 0.1668, -0.1102,  0.2499,  0.1753, -0.0994, -0.0689,  0.3255, -0.2859,\n",
      "          0.0018],\n",
      "        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan],\n",
      "        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan],\n",
      "        [ 0.0485, -0.2154,  0.2234,  0.2185, -0.1322,  0.2960, -0.1631,  0.1357,\n",
      "          0.0417],\n",
      "        [ 0.2172,  0.1153,  0.2752, -0.0966,  0.1375,  0.3043,  0.1885, -0.2570,\n",
      "          0.3103]])\n",
      "fc2.bias tensor([    nan,     nan,  0.3049,  0.2061,  0.0991,     nan,     nan, -0.2452,\n",
      "        -0.2545])\n",
      "NaNs in predicted parameters at epoch due to predparams 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=1000)\n",
    "\n",
    "# Define the maximum norm for the gradients\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Print model weights and biases\n",
    "    print(\"Model Weights and Biases:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.data)\n",
    "\n",
    "    predicted_parameters = model(input_3d)\n",
    "    if torch.isnan(predicted_parameters).any():\n",
    "        print(f\"NaNs in predicted parameters at epoch due to predparams {epoch}\")\n",
    "        break\n",
    "    \n",
    "    predicted_parameters_mean = torch.mean(predicted_parameters, dim=0)\n",
    "    print(' predicted params mean', predicted_parameters_mean)\n",
    "    predicted_2d = apply_camera_model(predicted_parameters_mean, input_3d)\n",
    "    if torch.isnan(predicted_2d).any():\n",
    "        print(f\"NaNs in predicted 2D points at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "    # print shapes of predicted_2d and target_2d\n",
    "    print('predicted_2d.shape:', predicted_2d.shape)\n",
    "    print('target_2d.shape:', target_2d.shape)\n",
    "    loss = criterion(predicted_2d, target_2d)\n",
    "    if torch.isnan(loss):\n",
    "        print(f\"NaNs in loss at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Perform backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Gradient clipping\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
